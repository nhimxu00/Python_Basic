{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dùng GA cho hàm: x1*x1 + x2*x2 + x3*x3 +x4*x4 + x5*x5\\\n",
    "# 1: Viết lại hàm generate_random_value() để sinh ra số thực trong khoảng [-20.20]\n",
    "def generate_random_value(bound = 20):\n",
    "    return (random.random()*2-1)*bound\n",
    "# 2: Viết lại hàm compute_fitness()\n",
    "def compute_loss(individual):\n",
    "    return sum(gen*gen for gen i individual)\n",
    "\n",
    "def compute_fitness(individual)\n",
    "    loss = compute_loss(individual)\n",
    "    fitness = 1/ (loss + 1)\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 194.2618841653385\n",
      "Best loss: 165.50978874049068\n",
      "Best loss: 164.6156688063705\n",
      "Best loss: 47.975395179109555\n",
      "Best loss: 47.975395179109555\n",
      "Best loss: 47.975395179109555\n",
      "Best loss: 47.975395179109555\n",
      "Best loss: 41.601814113965425\n",
      "Best loss: 34.45601937196222\n",
      "Best loss: 31.70886760363196\n",
      "Best loss: 24.237029338101973\n",
      "Best loss: 21.489877569771703\n",
      "Best loss: 21.489877569771703\n",
      "Best loss: 19.360838013617993\n",
      "Best loss: 14.88595662833085\n",
      "Best loss: 14.88595662833085\n",
      "Best loss: 14.88595662833085\n",
      "Best loss: 11.78234398779737\n",
      "Best loss: 11.78234398779737\n",
      "Best loss: 6.230453222604644\n",
      "Best loss: 6.230453222604644\n",
      "Best loss: 6.230453222604644\n",
      "Best loss: 6.100884644905681\n",
      "Best loss: 5.4097809579943625\n",
      "Best loss: 5.4097809579943625\n",
      "Best loss: 5.4097809579943625\n",
      "Best loss: 5.1378255769339285\n",
      "Best loss: 5.1378255769339285\n",
      "Best loss: 5.1378255769339285\n",
      "Best loss: 5.1378255769339285\n",
      "Best loss: 5.1378255769339285\n",
      "Best loss: 5.127891088057523\n",
      "Best loss: 5.127891088057523\n",
      "Best loss: 5.040270185217536\n",
      "Best loss: 4.985504284696052\n",
      "Best loss: 2.8186149875389632\n",
      "Best loss: 2.8186149875389632\n",
      "Best loss: 2.8186149875389632\n",
      "Best loss: 2.8186149875389632\n",
      "Best loss: 2.6890464098399995\n",
      "Best loss: 2.6890464098399995\n",
      "Best loss: 2.6890464098399995\n",
      "Best loss: 2.6890464098399995\n",
      "Best loss: 2.6890464098399995\n",
      "Best loss: 2.6890464098399995\n",
      "Best loss: 2.6890464098399995\n",
      "Best loss: 2.6890464098399995\n",
      "Best loss: 2.5909427517297687\n",
      "Best loss: 2.5909427517297687\n",
      "Best loss: 2.5909427517297687\n",
      "Best loss: 2.5909427517297687\n",
      "Best loss: 2.5909427517297687\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6168336545514296\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n",
      "Best loss: 0.6161685360285839\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3: Chỉnh lại giá trị tham sô của GA phù hợp\n",
    "import random\n",
    "n = 6                 # size of individual (chromosome)\n",
    "m = 50                # size of population\n",
    "n_generations = 100    # number of generations\n",
    "# để vẽ biểu đồ quá trình tối ưu\n",
    "losses = []\n",
    "def generate_random_value(bound = 20):\n",
    "    return (random.random()*2 - 1)*bound\n",
    "def compute_loss(individual):\n",
    "    return sum(gen*gen for gen in individual)\n",
    "def compute_fitness(individual):\n",
    "    loss =  compute_loss(individual)\n",
    "    fitness = 1 / (loss + 1)\n",
    "    return fitness\n",
    "def create_individual():\n",
    "    return [generate_random_value() for _ in range(n)]\n",
    "def crossover(individual1, individual2, crossover_rate = 0.9):\n",
    "    individual1_new = individual1.copy()\n",
    "    individual2_new = individual2.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        if random.random() < crossover_rate:\n",
    "            individual1_new[i] = individual2[i]\n",
    "            individual2_new[i] = individual1[i]            \n",
    "    \n",
    "    return individual1_new, individual2_new\n",
    "def mutate(individual, mutation_rate = 0.05):\n",
    "    individual_m = individual.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        if random.random() < mutation_rate:\n",
    "            individual_m[i] = generate_random_value()\n",
    "        \n",
    "    return individual_m\n",
    "def selection(sorted_old_population):    \n",
    "    index1 = random.randint(0, m-1)    \n",
    "    while True:\n",
    "        index2 = random.randint(0, m-1)    \n",
    "        if (index2 != index1):\n",
    "            break\n",
    "            \n",
    "    individual_s = sorted_old_population[index1]\n",
    "    if index2 > index1:\n",
    "        individual_s = sorted_old_population[index2]\n",
    "    \n",
    "    return individual_s \n",
    "def create_new_population(old_population, elitism=2, gen=1):\n",
    "    sorted_population = sorted(old_population, key=compute_fitness)\n",
    "        \n",
    "    if gen%1 == 0:\n",
    "        losses.append(compute_loss(sorted_population[m-1]))\n",
    "        print(\"Best loss:\", compute_loss(sorted_population[m-1]))      \n",
    "    \n",
    "    new_population = []\n",
    "    while len(new_population) < m-elitism:\n",
    "        # selection\n",
    "        individual_s1 = selection(sorted_population)\n",
    "        individual_s2 = selection(sorted_population) # duplication\n",
    "        \n",
    "        # crossover\n",
    "        individual_c1, individual_c2 = crossover(individual_s1, individual_s2)\n",
    "        \n",
    "        # mutation\n",
    "        individual_m1 = mutate(individual_c1)\n",
    "        individual_m2 = mutate(individual_c2)\n",
    "        \n",
    "        new_population.append(individual_m1)\n",
    "        new_population.append(individual_m2)            \n",
    "    \n",
    "    for ind in sorted_population[m-elitism:]:\n",
    "        new_population.append(ind.copy())\n",
    "    \n",
    "    return new_population\n",
    "population = [create_individual() for _ in range(m)]\n",
    "for i in range(n_generations):\n",
    "    population = create_new_population(population, 2, i)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses[:200], c = \"green\")\n",
    "plt.xlabel(\"Gennerations\")\n",
    "plt.ylabel(\"losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 91.18649207304568 [1.6519292007230568, 8.291637358770254]\n",
      "Best loss: 91.18649207304568 [1.6519292007230568, 8.291637358770254]\n",
      "Best loss: 91.18649207304568 [1.6519292007230568, 8.291637358770254]\n",
      "Best loss: 91.18649207304568 [1.6519292007230568, 8.291637358770254]\n",
      "Best loss: 91.18649207304568 [1.6519292007230568, 8.291637358770254]\n",
      "Best loss: 91.18649207304568 [1.6519292007230568, 8.291637358770254]\n",
      "Best loss: 91.18649207304568 [1.6519292007230568, 8.291637358770254]\n",
      "Best loss: 29.661648019901914 [0.05562668648833036, 7.481055348894916]\n",
      "Best loss: 29.661648019901914 [0.05562668648833036, 7.481055348894916]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 8.731668729666302 [1.6519292007230568, -1.3003468276244545]\n",
      "Best loss: 7.85411888107649 [1.6519292007230568, -0.22528220920479125]\n",
      "Best loss: 7.85411888107649 [1.6519292007230568, -0.22528220920479125]\n",
      "Best loss: 7.85411888107649 [1.6519292007230568, -0.22528220920479125]\n",
      "Best loss: 7.85411888107649 [1.6519292007230568, -0.22528220920479125]\n",
      "Best loss: 7.85411888107649 [1.6519292007230568, -0.22528220920479125]\n",
      "Best loss: 7.85411888107649 [1.6519292007230568, -0.22528220920479125]\n",
      "Best loss: 7.85411888107649 [1.6519292007230568, -0.22528220920479125]\n",
      "Best loss: 7.85411888107649 [1.6519292007230568, -0.22528220920479125]\n",
      "Best loss: 7.85411888107649 [1.6519292007230568, -0.22528220920479125]\n",
      "Best loss: 7.85411888107649 [1.6519292007230568, -0.22528220920479125]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.333996494201914 [1.6519292007230568, -0.6832564866678714]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 7.103705100322383 [1.6519292007230568, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 6.458028777411607 [1.4111071224850447, -0.5579765920031177]\n",
      "Best loss: 5.549093113397232 [1.4111071224850447, 0.5308056955325657]\n",
      "Best loss: 5.549093113397232 [1.4111071224850447, 0.5308056955325657]\n",
      "Best loss: 5.549093113397232 [1.4111071224850447, 0.5308056955325657]\n",
      "Best loss: 5.549093113397232 [1.4111071224850447, 0.5308056955325657]\n",
      "Best loss: 5.549093113397232 [1.4111071224850447, 0.5308056955325657]\n",
      "Best loss: 5.549093113397232 [1.4111071224850447, 0.5308056955325657]\n",
      "Best loss: 5.549093113397232 [1.4111071224850447, 0.5308056955325657]\n",
      "Best loss: 5.549093113397232 [1.4111071224850447, 0.5308056955325657]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.331842979802867 [1.4111071224850447, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 4.239619673493433 [1.4030946718934345, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.3313127772680673 [1.3007112029414403, 0.26423231876342435]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.1195765238516104 [1.3007112029414403, 0.5198724515267372]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0668224357296614 [1.3007112029414403, 0.38940958332609465]\n",
      "Best loss: 3.0611859458559794 [1.3007112029414403, 0.46885337869684296]\n",
      "Best loss: 3.0611859458559794 [1.3007112029414403, 0.46885337869684296]\n",
      "Best loss: 3.0611859458559794 [1.3007112029414403, 0.46885337869684296]\n",
      "Best loss: 3.0611859458559794 [1.3007112029414403, 0.46885337869684296]\n",
      "Best loss: 3.0611859458559794 [1.3007112029414403, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 3.0116622784304545 [1.2464036461653727, 0.46885337869684296]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.877182281827688 [1.2464036461653727, 0.5360933769982257]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.7831917319823014 [1.2464036461653727, 0.7652321004418372]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n",
      "Best loss: 2.765990599559325 [1.2464036461653727, 0.7346266951765434]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "n = 2                  # size of individual (chromosome)\n",
    "m = 100                # size of population\n",
    "n_generations = 2000   # number of generations\n",
    "losses = []            # để vẽ biểu đồ quá trình tối ưu\n",
    "# Hàm load data\n",
    "def load_data():\n",
    "    # kết nối với file\n",
    "    file = open('data.csv','r')\n",
    "    # readlines giúp việc đọc file theo từng dòng , mỗi dòng là 1 chuỗi\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    areas  = []\n",
    "    prices = []\n",
    "    for i in range(10): \n",
    "        string = lines[i].split(',')\n",
    "        areas.append(float(string[0]))\n",
    "        prices.append(float(string[1]))\n",
    "    # Đóng kết nối với file\n",
    "    file.close()\n",
    "    \n",
    "    return areas, prices\n",
    "# load data\n",
    "areas, prices = load_data()\n",
    "def generate_random_value(bound = 200):\n",
    "    return (random.random()-0.5)*bound\n",
    "def compute_loss(individual):\n",
    "    result = 65534\n",
    "    \n",
    "    a = individual[0]\n",
    "    b = individual[1]    \n",
    "    estimated_prices = [a*x + b for x in areas]\n",
    "    \n",
    "    # all prices should be positive numbers\n",
    "    num_negetive_prices = sum(p < 0 for p in estimated_prices)\n",
    "    if num_negetive_prices == 0:        \n",
    "        losses = [abs(y_est-y_gt) for y_est, y_gt in zip(estimated_prices, prices)]\n",
    "        result = sum(losses)\n",
    "    \n",
    "    return result\n",
    "def compute_fitness(individual):\n",
    "    loss = compute_loss(individual)\n",
    "    fitness = 1 / (loss + 1)\n",
    "    return fitness\n",
    "def create_individual():\n",
    "    return [generate_random_value() for _ in range(n)]\n",
    "def crossover(individual1, individual2, crossover_rate = 0.9):\n",
    "    individual1_new = individual1.copy()\n",
    "    individual2_new = individual2.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        if random.random() < crossover_rate:\n",
    "            individual1_new[i] = individual2[i]\n",
    "            individual2_new[i] = individual1[i]            \n",
    "    \n",
    "    return individual1_new, individual2_new\n",
    "def mutate(individual, mutation_rate = 0.05):\n",
    "    individual_m = individual.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        if random.random() < mutation_rate:\n",
    "            individual_m[i] = generate_random_value()\n",
    "        \n",
    "    return individual_m\n",
    "def selection(sorted_old_population):    \n",
    "    index1 = random.randint(0, m-1)    \n",
    "    while True:\n",
    "        index2 = random.randint(0, m-1)    \n",
    "        if (index2 != index1):\n",
    "            break\n",
    "            \n",
    "    individual_s = sorted_old_population[index1]\n",
    "    if index2 > index1:\n",
    "        individual_s = sorted_old_population[index2]\n",
    "    \n",
    "    return individual_s \n",
    "def create_new_population(old_population, elitism=2, gen=1):\n",
    "    sorted_population = sorted(old_population, key=compute_fitness)\n",
    "        \n",
    "    if gen%1 == 0:\n",
    "        losses.append(compute_loss(sorted_population[m-1]))\n",
    "        print(\"Best loss:\", compute_loss(sorted_population[m-1]), sorted_population[m-1])      \n",
    "    \n",
    "    new_population = []\n",
    "    while len(new_population) < m-elitism:\n",
    "        # selection\n",
    "        individual_s1 = selection(sorted_population)\n",
    "        individual_s2 = selection(sorted_population) # duplication\n",
    "        \n",
    "        # crossover\n",
    "        individual_c1, individual_c2 = crossover(individual_s1, individual_s2)\n",
    "        \n",
    "        # mutation\n",
    "        individual_m1 = mutate(individual_c1)\n",
    "        individual_m2 = mutate(individual_c2)\n",
    "        \n",
    "        new_population.append(individual_m1)\n",
    "        new_population.append(individual_m2)            \n",
    "    \n",
    "    for ind in sorted_population[m-elitism:]:\n",
    "        new_population.append(ind.copy())\n",
    "    \n",
    "    return new_population\n",
    "population = [create_individual() for _ in range(m)]\n",
    "for i in range(n_generations):\n",
    "    population = create_new_population(population, 2, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses[:200], c = \"green\")\n",
    "plt.xlabel(\"Gennerations\")\n",
    "plt.ylabel(\"losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
